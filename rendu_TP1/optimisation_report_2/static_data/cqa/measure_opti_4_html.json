{
  "_cqa_text_report":
    {
      "_objects":
        {
          "image_vec_align":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/vec_align.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_128.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_128":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_128.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_8x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/8x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_2x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_2x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/2x64_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x64_256":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x64_256.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_1x32_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/1x32_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_4x64_512":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/4x64_512.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_row_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/row_maj.svg",
              "size":
                {
                  "x": 500
                }
            },
          "image_col_maj":
            {
              "type": "image",
              "format": "url",
              "data": "../images/cqa/col_maj.svg",
              "size":
                {
                  "x": 500
                }
            }
        },
      "AVG":
        {
          "hint":
            [
              {
                "workaround": "<ul><li>Try to reorganize arrays of structures to structures of arrays</li><li>Consider to permute loops (see vectorization gain report)</li></ul>",
                "details": "<ul><li>Constant non-unit stride: 2 occurrence(s)</li></ul>Non-unit stride (uncontiguous) accesses are not efficiently using data caches\n",
                "title": "Slow data structures access",
                "txt": "Detected data structures (typically arrays) that cannot be efficiently read/written"
              },
              {
                "title": "Type of elements and instruction set",
                "txt": "8 AVX instructions are processing arithmetic or math operations on double precision FP elements in vector mode (four at a time).\n"
              },
              {
                "title": "Matching between your loop (in the source code) and the binary loop",
                "txt": "The binary loop is composed of 32 FP arithmetical operations:\n<ul><li>32: addition or subtraction</li></ul>The binary loop is loading 256 bytes (32 double precision FP elements)."
              },
              {
                "title": "Arithmetic intensity",
                "txt": "Arithmetic intensity is 0.12 FP operations per loaded or stored byte."
              },
              {
                "workaround": "Unroll your loop if trip count is significantly higher than target unroll factor and if some data references are common to consecutive iterations. This can be done manually. Or by recompiling with -funroll-loops and/or -floop-unroll-and-jam. Or with the unroll (resp. unroll_and_jam) directive on top of the inner (resp. surrounding) loop. You can enforce an unroll factor: #pragma GCC unroll N",
                "title": "Unroll opportunity",
                "txt": "Loop is data access bound."
              }
            ],
          "expert":
            [
              {
                "title": "General properties",
                "txt": "<table><tr><td>nb instructions</td><td>11</td></tr><tr><td>nb uops</td><td>10</td></tr><tr><td>loop length</td><td>59</td></tr><tr><td>used x86 registers</td><td>2</td></tr><tr><td>used mmx registers</td><td>0</td></tr><tr><td>used xmm registers</td><td>0</td></tr><tr><td>used ymm registers</td><td>8</td></tr><tr><td>used zmm registers</td><td>0</td></tr><tr><td>nb stack references</td><td>0</td></tr></table>"
              },
              {
                "title": "Front-end",
                "txt": "ASSUMED MACRO FUSION\nFIT IN UOP CACHE\n<table><tr><td>micro-operation queue</td><td>1.67 cycles</td></tr><tr><td>front end</td><td>1.67 cycles</td></tr></table>"
              },
              {
                "title": "Back-end",
                "txt": "<table><tr><th>      </th><th>ALU0/BRU0</th><th>ALU1</th><th>ALU2</th><th>ALU3/BRU1</th><th>AGU0</th><th>AGU1</th><th>AGU2</th><th>FP0</th><th>FP1</th><th>FP2</th><th>FP3</th></tr><tr><td>uops</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.50</td><td>4.00</td><td>4.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>4.00</td><td>4.00</td></tr><tr><td>cycles</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.50</td><td>4.00</td><td>4.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>4.00</td><td>4.00</td></tr></table>\nExecution ports to units layout:\n<ul><li>ALU0/BRU0: ALU, BRU</li><li>ALU1: ALU</li><li>ALU2: ALU</li><li>ALU3/BRU1: ALU, BRU</li><li>AGU0 (256 bits): store address, load</li><li>AGU1 (256 bits): store address, load</li><li>AGU2: store address</li><li>FP0 (256 bits): VPU</li><li>FP1 (256 bits): VPU</li><li>FP2 (256 bits): VPU, FP store data</li><li>FP3 (256 bits): VPU, DIV/SQRT</li></ul>\n<table><tr><td>Cycles executing div or sqrt instructions</td><td>NA</td></tr><tr><td>Cycles loading/storing data</td><td>4.00</td></tr><tr><td>Longest recurrence chain latency (RecMII)</td><td>24.00</td></tr></table>"
              },
              {
                "title": "Cycles summary",
                "txt": "<table><tr><td>Front-end</td><td>1.67</td></tr><tr><td>Dispatch</td><td>4.00</td></tr><tr><td>Data deps.</td><td>24.00</td></tr><tr><td>Overall L1</td><td>24.00</td></tr></table>"
              },
              {
                "title": "Vectorization ratios",
                "txt": "<table><tr><td>all</td><td>100%</td></tr><tr><td>load</td><td>100%</td></tr><tr><td>store</td><td>NA (no store vectorizable/vectorized instructions)</td></tr><tr><td>mul</td><td>NA (no mul vectorizable/vectorized instructions)</td></tr><tr><td>add-sub</td><td>100%</td></tr><tr><td>fma</td><td>NA (no fma vectorizable/vectorized instructions)</td></tr><tr><td>div/sqrt</td><td>NA (no div/sqrt vectorizable/vectorized instructions)</td></tr><tr><td>other</td><td>NA (no other vectorizable/vectorized instructions)</td></tr></table>"
              },
              {
                "title": "Vector efficiency ratios",
                "txt": "<table><tr><td>all</td><td>100%</td></tr><tr><td>load</td><td>100%</td></tr><tr><td>store</td><td>NA (no store vectorizable/vectorized instructions)</td></tr><tr><td>mul</td><td>NA (no mul vectorizable/vectorized instructions)</td></tr><tr><td>add-sub</td><td>100%</td></tr><tr><td>fma</td><td>NA (no fma vectorizable/vectorized instructions)</td></tr><tr><td>div/sqrt</td><td>NA (no div/sqrt vectorizable/vectorized instructions)</td></tr><tr><td>other</td><td>NA (no other vectorizable/vectorized instructions)</td></tr></table>"
              },
              {
                "title": "Cycles and memory resources usage",
                "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 24.00 cycles. At this rate:\n<ul><li>16% of peak load performance is reached (10.67 out of 64.00 bytes loaded per cycle (GB/s @ 1GHz))</li></ul>"
              },
              {
                "title": "Front-end bottlenecks",
                "txt": "Found no such bottlenecks."
              },
              {
                "title": "ASM code",
                "txt": "In the binary file, the address of the loop is: 17c8\n\n<table><tr><th>Instruction</th><th>Nb FU</th><th>ALU0/BRU0</th><th>ALU1</th><th>ALU2</th><th>ALU3/BRU1</th><th>AGU0</th><th>AGU1</th><th>AGU2</th><th>FP0</th><th>FP1</th><th>FP2</th><th>FP3</th><th>Latency</th><th>Recip. throughput</th><th>Vectorization</th></tr><tr><td>VADDPD (%RAX),%YMM9,%YMM11</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>ADD $0x100,%RAX</td><td>1</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.25</td><td>N/A</td></tr><tr><td>VADDPD -0xe0(%RAX),%YMM11,%YMM12</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0xc0(%RAX),%YMM12,%YMM13</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0xa0(%RAX),%YMM13,%YMM14</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x80(%RAX),%YMM14,%YMM15</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x60(%RAX),%YMM15,%YMM7</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x40(%RAX),%YMM7,%YMM6</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x20(%RAX),%YMM6,%YMM9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>CMP %RAX,%RDX</td><td>1</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.25</td><td>N/A</td></tr><tr><td>JNE 17c8 &lt;main+0x6f8&gt;</td><td>1</td><td>0.50</td><td>0</td><td>0</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.50</td><td>N/A</td></tr></table>"
              }
            ],
          "header":
            [
            "5% of peak computational performance is used (1.33 out of 24.00 FLOP per cycle (GFLOPS @ 1GHz))"
            ],
          "brief":
            [

            ],
          "gain":
            [
              {
                "details": "All SSE/AVX instructions are used in vector version (process two or more data elements in vector registers).\n",
                "title": "Vectorization",
                "txt": "Your loop is fully vectorized, using full register length.\n"
              },
              {
                "title": "Execution units bottlenecks",
                "txt": "Found no such bottlenecks but see expert reports for more complex bottlenecks."
              }
            ],
          "potential":
            [

            ]
        },
      "paths":
        [
          {
            "hint":
              [
                {
                  "workaround": "<ul><li>Try to reorganize arrays of structures to structures of arrays</li><li>Consider to permute loops (see vectorization gain report)</li></ul>",
                  "details": "<ul><li>Constant non-unit stride: 2 occurrence(s)</li></ul>Non-unit stride (uncontiguous) accesses are not efficiently using data caches\n",
                  "title": "Slow data structures access",
                  "txt": "Detected data structures (typically arrays) that cannot be efficiently read/written"
                },
                {
                  "title": "Type of elements and instruction set",
                  "txt": "8 AVX instructions are processing arithmetic or math operations on double precision FP elements in vector mode (four at a time).\n"
                },
                {
                  "title": "Matching between your loop (in the source code) and the binary loop",
                  "txt": "The binary loop is composed of 32 FP arithmetical operations:\n<ul><li>32: addition or subtraction</li></ul>The binary loop is loading 256 bytes (32 double precision FP elements)."
                },
                {
                  "title": "Arithmetic intensity",
                  "txt": "Arithmetic intensity is 0.12 FP operations per loaded or stored byte."
                },
                {
                  "workaround": "Unroll your loop if trip count is significantly higher than target unroll factor and if some data references are common to consecutive iterations. This can be done manually. Or by recompiling with -funroll-loops and/or -floop-unroll-and-jam. Or with the unroll (resp. unroll_and_jam) directive on top of the inner (resp. surrounding) loop. You can enforce an unroll factor: #pragma GCC unroll N",
                  "title": "Unroll opportunity",
                  "txt": "Loop is data access bound."
                }
              ],
            "expert":
              [
                {
                  "title": "General properties",
                  "txt": "<table><tr><td>nb instructions</td><td>11</td></tr><tr><td>nb uops</td><td>10</td></tr><tr><td>loop length</td><td>59</td></tr><tr><td>used x86 registers</td><td>2</td></tr><tr><td>used mmx registers</td><td>0</td></tr><tr><td>used xmm registers</td><td>0</td></tr><tr><td>used ymm registers</td><td>8</td></tr><tr><td>used zmm registers</td><td>0</td></tr><tr><td>nb stack references</td><td>0</td></tr></table>"
                },
                {
                  "title": "Front-end",
                  "txt": "ASSUMED MACRO FUSION\nFIT IN UOP CACHE\n<table><tr><td>micro-operation queue</td><td>1.67 cycles</td></tr><tr><td>front end</td><td>1.67 cycles</td></tr></table>"
                },
                {
                  "title": "Back-end",
                  "txt": "<table><tr><th>      </th><th>ALU0/BRU0</th><th>ALU1</th><th>ALU2</th><th>ALU3/BRU1</th><th>AGU0</th><th>AGU1</th><th>AGU2</th><th>FP0</th><th>FP1</th><th>FP2</th><th>FP3</th></tr><tr><td>uops</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.50</td><td>4.00</td><td>4.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>4.00</td><td>4.00</td></tr><tr><td>cycles</td><td>0.50</td><td>0.50</td><td>0.50</td><td>0.50</td><td>4.00</td><td>4.00</td><td>0.00</td><td>0.00</td><td>0.00</td><td>4.00</td><td>4.00</td></tr></table>\nExecution ports to units layout:\n<ul><li>ALU0/BRU0: ALU, BRU</li><li>ALU1: ALU</li><li>ALU2: ALU</li><li>ALU3/BRU1: ALU, BRU</li><li>AGU0 (256 bits): store address, load</li><li>AGU1 (256 bits): store address, load</li><li>AGU2: store address</li><li>FP0 (256 bits): VPU</li><li>FP1 (256 bits): VPU</li><li>FP2 (256 bits): VPU, FP store data</li><li>FP3 (256 bits): VPU, DIV/SQRT</li></ul>\n<table><tr><td>Cycles executing div or sqrt instructions</td><td>NA</td></tr><tr><td>Cycles loading/storing data</td><td>4.00</td></tr><tr><td>Longest recurrence chain latency (RecMII)</td><td>24.00</td></tr></table>"
                },
                {
                  "title": "Cycles summary",
                  "txt": "<table><tr><td>Front-end</td><td>1.67</td></tr><tr><td>Dispatch</td><td>4.00</td></tr><tr><td>Data deps.</td><td>24.00</td></tr><tr><td>Overall L1</td><td>24.00</td></tr></table>"
                },
                {
                  "title": "Vectorization ratios",
                  "txt": "<table><tr><td>all</td><td>100%</td></tr><tr><td>load</td><td>100%</td></tr><tr><td>store</td><td>NA (no store vectorizable/vectorized instructions)</td></tr><tr><td>mul</td><td>NA (no mul vectorizable/vectorized instructions)</td></tr><tr><td>add-sub</td><td>100%</td></tr><tr><td>fma</td><td>NA (no fma vectorizable/vectorized instructions)</td></tr><tr><td>div/sqrt</td><td>NA (no div/sqrt vectorizable/vectorized instructions)</td></tr><tr><td>other</td><td>NA (no other vectorizable/vectorized instructions)</td></tr></table>"
                },
                {
                  "title": "Vector efficiency ratios",
                  "txt": "<table><tr><td>all</td><td>100%</td></tr><tr><td>load</td><td>100%</td></tr><tr><td>store</td><td>NA (no store vectorizable/vectorized instructions)</td></tr><tr><td>mul</td><td>NA (no mul vectorizable/vectorized instructions)</td></tr><tr><td>add-sub</td><td>100%</td></tr><tr><td>fma</td><td>NA (no fma vectorizable/vectorized instructions)</td></tr><tr><td>div/sqrt</td><td>NA (no div/sqrt vectorizable/vectorized instructions)</td></tr><tr><td>other</td><td>NA (no other vectorizable/vectorized instructions)</td></tr></table>"
                },
                {
                  "title": "Cycles and memory resources usage",
                  "txt": "Assuming all data fit into the L1 cache, each iteration of the binary loop takes 24.00 cycles. At this rate:\n<ul><li>16% of peak load performance is reached (10.67 out of 64.00 bytes loaded per cycle (GB/s @ 1GHz))</li></ul>"
                },
                {
                  "title": "Front-end bottlenecks",
                  "txt": "Found no such bottlenecks."
                },
                {
                  "title": "ASM code",
                  "txt": "In the binary file, the address of the loop is: 17c8\n\n<table><tr><th>Instruction</th><th>Nb FU</th><th>ALU0/BRU0</th><th>ALU1</th><th>ALU2</th><th>ALU3/BRU1</th><th>AGU0</th><th>AGU1</th><th>AGU2</th><th>FP0</th><th>FP1</th><th>FP2</th><th>FP3</th><th>Latency</th><th>Recip. throughput</th><th>Vectorization</th></tr><tr><td>VADDPD (%RAX),%YMM9,%YMM11</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>ADD $0x100,%RAX</td><td>1</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.25</td><td>N/A</td></tr><tr><td>VADDPD -0xe0(%RAX),%YMM11,%YMM12</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0xc0(%RAX),%YMM12,%YMM13</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0xa0(%RAX),%YMM13,%YMM14</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x80(%RAX),%YMM14,%YMM15</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x60(%RAX),%YMM15,%YMM7</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x40(%RAX),%YMM7,%YMM6</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>VADDPD -0x20(%RAX),%YMM6,%YMM9</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0.50</td><td>0.50</td><td>3</td><td>0.50</td><td>vect (100.0%)</td></tr><tr><td>CMP %RAX,%RDX</td><td>1</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0.25</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.25</td><td>N/A</td></tr><tr><td>JNE 17c8 &lt;main+0x6f8&gt;</td><td>1</td><td>0.50</td><td>0</td><td>0</td><td>0.50</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0.50</td><td>N/A</td></tr></table>"
                }
              ],
            "header":
              [
              "5% of peak computational performance is used (1.33 out of 24.00 FLOP per cycle (GFLOPS @ 1GHz))"
              ],
            "brief":
              [

              ],
            "gain":
              [
                {
                  "details": "All SSE/AVX instructions are used in vector version (process two or more data elements in vector registers).\n",
                  "title": "Vectorization",
                  "txt": "Your loop is fully vectorized, using full register length.\n"
                },
                {
                  "title": "Execution units bottlenecks",
                  "txt": "Found no such bottlenecks but see expert reports for more complex bottlenecks."
                }
              ],
            "potential":
              [

              ]
          }
        ],
      "common":
        {
          "header":
            [
            "The loop is defined in /home/mac/rendu_AOC/rendu_TP1/driver_opti.c:22-23.\n",
            "The related source loop is multi-versionned."
            ],
          "nb_paths": 1
        }
    }
}
